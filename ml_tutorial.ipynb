{
  "cells": [
    {
      "metadata": {
        "_uuid": "a6ad42597ffdbeec1fae13d57a855218b5a072b7"
      },
      "cell_type": "markdown",
      "source": "# Kernel powstal na podstawie tutorialu [Machine Learningu ](www.kaggle.com/dansbecker/learn-machine-learning) na Kaggle\n\n## Zawiera glowne kroki zawarte w Intermediate Machine Learning z kilkoma zmianami, by operowac na tych samych danych i nie powtarzac tych samych operacji w krokach 1-4. Czesc 7. operuje na innym datasetcie.\n### Zawiera:\n\n1.  Oczyszczanie danych i imputacje\n\n2. One-hot encoding\n\n3. XGBoosting\n\n4. Wykresy czesciowej zaleznosci (Partial Dependence Plots)\n\n5. Tworzenie PIPELINE\n\n6. Cross Validation\n\n7. Data Leakage"
    },
    {
      "metadata": {
        "_uuid": "678302d7a362f91a46268859ef4c16b2579897cd"
      },
      "cell_type": "markdown",
      "source": "# 1. Oczyszczanie danych z pustych wartości przez usuwanie kolumn lub imputację"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nmelb_data = pd.read_csv('../input/melbourne-housing-snapshot/melb_data.csv') #wczytanie danych\n\nfrom sklearn.ensemble import RandomForestRegressor #las losowy\nfrom sklearn.metrics import mean_absolute_error #MAE - do obliczen absolutnego bledu\nfrom sklearn.model_selection import train_test_split #podzial na train i test\n\nmelb_target=melb_data.Price #nasz target - cena domu\nmelb_predictors=melb_data.drop(['Price'], axis=1) #nasze cechy, ktore uzywamy do przewidywania ceny (wyrzucenie kolumny z cena)\n \n#melb_numeric_predictors = melb_predictors.select_dtypes(exclude=['object']) #odrzucenie nienumreycznych wartosci",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Mala modyfikacja, by zrealizowac krok 2 z tutorialu level 2 One-hot encoding, podzielilem train_X i val_X na wartosci numeryczne i nienumeryczne\n#by po imputacji moc dalej operowac na pelnym zbiorze i przeprowadzic one-hot encoding\n\n#train_X, val_X, train_y, val_y = train_test_split(melb_numeric_predictors, melb_target, random_state=0) #podzial na train i test, pseudolosowo\ntrain_X_all, val_X_all, train_y, val_y = train_test_split(melb_predictors, melb_target, random_state=0) #podzial na train i test, pseudolosowo\n\ntrain_X = train_X_all.select_dtypes(exclude=['object'])#numeryczne wartosci\nval_X=val_X_all.select_dtypes(exclude=['object']) #numeryczne wartosci\n\ntrain_X_str=train_X_all.select_dtypes(include=['object']) #wartosci nienumeryczne\nval_X_str=val_X_all.select_dtypes(include=['object']) #wartosci nienumeryczne",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "0141363c54cd3068f836accfbaf443c6e84cf7df"
      },
      "cell_type": "code",
      "source": "def score_dataset(train_X, val_X, train_y, val_y):\n    '''Funkcja zwaracaja MAE na podstawie wprowadzonych train i testow. Predykcja z uzyciem lasu losowego'''\n    melbourne_model=RandomForestRegressor() #las losowy jako model\n    melbourne_model.fit(train_X, train_y) #trening \n    val_predictions=melbourne_model.predict(val_X) #predykcja na zbiorze testowym\n    return mean_absolute_error(val_y, val_predictions) #obliczenie MAE",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "eb4725993bf1aef8a46d8ac9cc8fa66691c87b9e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#TEST MODELU Z ODRZUCENIEM KOLUMN ZWIERAJACYCH PUSTE KOMORKI\n#train_data.dropna(axis=0, subset=['SalePrice'], inplace=True) #wyrzucenie wierszy, ktore nie maja podanej ceny\ncols_with_missing = [col for col in train_X.columns #przypisanie, w ktorych kolumnach brakuje danych\n                                 if train_X[col].isnull().any()]\nreduced_X_train = train_X.drop(cols_with_missing, axis=1)#wyrzucenie kolum z brakujacymi danymi z train\nreduced_X_test  = val_X.drop(cols_with_missing, axis=1)#jw tylko z test\nprint(\"Mean Absolute Error z wyrzuceniem kolumn:\")\nprint(score_dataset(reduced_X_train, reduced_X_test, train_y, val_y))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5583601ac77d45fb652576a682cc1c2019fe329d",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#TEST MODELU DLA IMPUTACJI W PUSTE MIEJSCA\nfrom sklearn.impute import SimpleImputer #wczytanie imputora\nmy_imputer = SimpleImputer()\nimputed_X_train = my_imputer.fit_transform(train_X)#imputacja pustych pol w zbiorze treningowym\nimputed_X_test = my_imputer.transform(val_X)#imputacja pustych pol w zbiorze testowym\nprint(\"Mean Absolute Error z imputacji:\")\nprint(score_dataset(imputed_X_train, imputed_X_test, train_y, val_y)) #obliczenie MAE",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0c88342bd0533b70f56d1bc90ef24d2122da0bb9",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#TEST MODELU DLA IMPUTACJI W PUSTE MIEJSCA + WSKAZANIE KOLUMN, GDZIE SĄ PUSTE MIEJSCA\nimputed_X_train_plus = train_X.copy() #kopiowanie\nimputed_X_test_plus = val_X.copy()\n\ncols_with_missing = [col for col in train_X.columns #kolumny z brakujacymi danymi\n                                 if train_X[col].isnull().any()]\n\n\ncolumns_missing_names=[]#przechowywanie nazwy kolumn z was_missing do pozniejszego nazwania DataFrame po imputacji\nfor col in cols_with_missing: #dodanie kolumn z informacja, gdzie brakuje danych, zeby wiedziec, ze zostaly zastapione przez imputer\n    imputed_X_train_plus[col + '_was_missing'] = imputed_X_train_plus[col].isnull() #isnull zwraca bool\n    imputed_X_test_plus[col + '_was_missing'] = imputed_X_test_plus[col].isnull()\n    columns_missing_names.append(col + '_was_missing')\n\n# Imputacja w miejsce pustych w zbiorze treningowym i testowym\nmy_imputer = SimpleImputer()\nimputed_X_train_plus = my_imputer.fit_transform(imputed_X_train_plus)#nauka na zbiorze treningowym (oblicznenie sredniej) i transformacja (imputacja)\nimputed_X_test_plus = my_imputer.transform(imputed_X_test_plus)\n\nprint(\"MAE dla imputacji z informacja o miejscu imputacji\")\nprint(score_dataset(imputed_X_train_plus, imputed_X_test_plus, train_y, val_y))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bad33447908aa75a08796f9c08c8941e5d493db2",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Zmiana numpy array na dataframe po imputacji\nimputed_X_train = pd.DataFrame(imputed_X_train,columns=train_X.columns, index=train_X.index)\nimputed_X_test = pd.DataFrame(imputed_X_test,columns=val_X.columns, index=val_X.index)\n#print(imputed_X_train_plus.isnull().any()) #sprawdzenie, czy nie ma zadnych NaNow po stworzeniu DataFrame\n#print(imputed_X_test_plus.isnull().any())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "fcb762ddfb8aee3c91f83c78405555ab2d41a1fe"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4a888c20f9edd59f04f157b430e5423fb33b70cf"
      },
      "cell_type": "markdown",
      "source": "# 2. ONE-HOT ENCODING \n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cacf89c8b971c4cbccf140295c22fc3e27857b89",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#ONE-HOT ENCODING - DRUGA CZESC TUTORIALU\n\n#By operowac na tych samych danych, w 2-ej cell wprowadzono podzial na zmienne numeryczne (train_X, val_X) i nienumeryczne (train_X_str, val_X_str)\n\n#Sprawdzenie, czy zadna z wartosci nienumerycznych nie ma pustych miejsc\n#print(train_X_str.isnull().any()) #Odkomentuj, jesli chcesz sprawdzic, ktore kolumny zawieraja puste miejsca\n#print(val_X_str.isnull().any())\n\n#Odrzucenie kolumn z pustymi miejscami analogicznie jak w wczesniej dla testu dla wartosci numerycznych\ncols_with_missing_str = [col for col in train_X_str.columns #przypisanie, w ktorych kolumnach brakuje danych\n                                 if train_X_str[col].isnull().any()]\nreduced_X_train_str = train_X_str.drop(cols_with_missing_str, axis=1)#wyrzucenie kolum z brakujacymi danymi z train_str\nreduced_X_test_str = val_X_str.drop(cols_with_missing_str, axis=1)#wyrzucenie kolum z brakujacymi danymi z test_str\n#print(reduced_X_train_str.isnull().any()) #Odkomentuj, jesli chcesz sprawdzic, ktore kolumny zawieraja puste miejsca\n#print(reduced_X_test_str.isnull().any())\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "27d17afe87c9479249a45c2567249563cc6b8a76",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Polaczenie dataframe po imputacji (numerycznego) i nienumerycznego\nX_train_appended = pd.concat([imputed_X_train, reduced_X_train_str], axis=1, sort=False) #polaczenie df numerycznych i nienumerycznych dla train\nX_test_appended = pd.concat([imputed_X_test, reduced_X_test_str], axis=1, sort=False) #polaczenie df numerycznych i nienumerycznych dla test",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c0372a07c2694851296ac72c9fc024860b30e0a9",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Teraz mozna przeprowadzic tutorial dla one-encodingu, bez pustych wartosci\n#Powtarzam szukanie wartosci numerycznych i nienumerycznych wg tutka, tylko by zapamietac schemat :)\n\n#kolumny z wartosciami nienumerycznymi i unikalnymi (max 9 powtarzalnych nazw)\nlow_cardinality_cols = [cname for cname in X_train_appended.columns if \n                                X_train_appended[cname].nunique() < 10 and #mniej niz 9 unikalnych wartosci\n                                X_train_appended[cname].dtype == \"object\"] #typ nienumeryczny\nnumeric_cols = [cname for cname in X_train_appended.columns if \n                                X_train_appended[cname].dtype in ['int64', 'float64']] #typ numeryczny\nmy_cols = low_cardinality_cols + numeric_cols #poloaczenie nazw kolumn\ntrain_predictors = X_train_appended[my_cols]\ntest_predictors = X_test_appended[my_cols]\n\n#Sprawdzenie otrzymanego dataframa\npd.set_option('display.max_columns', None) #ustawienie wyswietlania wszystkich kolumn na pandasie\nprint(train_predictors.head())\nprint(\"Typ danych:\")\ntrain_predictors.dtypes.sample(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6b789a6c40a4394eca4dab6b957fc14a575e3456",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#one hot encoding\none_hot_encoded_training_predictors = pd.get_dummies(train_predictors) #get_dummien zasteluje wartosci nienumeryczne wartosciami 0-1 po utworzeniu nowych kolumn",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "24d618315d08506da39a18abfd6264285674c28e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Test z one-hot encodingiem i bez, porownanie wynikow\nfrom sklearn.model_selection import cross_val_score #import cv\nfrom sklearn.ensemble import RandomForestRegressor\n\ndef get_mae(X, y):#funkcja zwracajaca MAE\n    # multiple by -1 to make positive MAE score instead of neg value returned as sklearn convention\n    return -1 * cross_val_score(RandomForestRegressor(50),  #uzycie cross_validation, las losowy z 50 drzewami\n                                X, y, \n                                scoring = 'neg_mean_absolute_error').mean() #obliczenie sredniego bledu\n\npredictors_without_categoricals = train_predictors.select_dtypes(exclude=['object']) #predyktory tylko numeryczne \ntarget=train_y #target==wartosc y (cena)\n\nmae_without_categoricals = get_mae(predictors_without_categoricals, target)#MAE bez wartosci nienumerycznych\n\nmae_one_hot_encoded = get_mae(one_hot_encoded_training_predictors, target) #MAE z wartosciami nienumerycznymi zastapionymi one-hotami\n\nprint('Mean Absolute Error dla wartosci numerycznych: ' + str(int(mae_without_categoricals)))\nprint('Mean Abslute Error dla One-Hot Encoding: ' + str(int(mae_one_hot_encoded)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ad0b9441f446b690aca4db00e9e1bc2c581d324f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#zapewnienie takiego samego ukladu one-hot encodingu dla zbioru treningowego i testowego\none_hot_encoded_training_predictors = pd.get_dummies(train_predictors)\none_hot_encoded_test_predictors = pd.get_dummies(test_predictors)\nfinal_train, final_test = one_hot_encoded_training_predictors.align(one_hot_encoded_test_predictors,\n                                                                    join='left', \n                                                                    axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "de7cf9040be6df0022ceaf072489b3b704adbc78"
      },
      "cell_type": "markdown",
      "source": "# 3. XGBOOSTING"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7e9f93e935616f4b656d37a6ff54f5c340e44fd7",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from xgboost import XGBRegressor #wybranie modelu XGBregresora\nmy_model = XGBRegressor()\n\n#imputed_X_train - zbior treningowy numeryczny po imputacji z 1szej czesci, train_y - tez z 1szej czesci\nmy_model.fit(imputed_X_train, train_y, verbose=10) #verbose - czy drukowac wyniki do konsoli i co ile",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d2941c2d0ce86657f75112c52b1a89e74fc7a53",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# predykcja\npredictions = my_model.predict(imputed_X_test)\nprint(\"Mean Absolute Error : \" + str(mean_absolute_error(predictions, val_y)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e99f8340ff9c3756ae17326808cf19e07a9f6b1e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Tuning wartosci XGBRegressora\nmy_model = XGBRegressor(n_estimators=1000) #n_estimators=1000 ile drzew (iteracji?)\nmy_model.fit(imputed_X_train, train_y, early_stopping_rounds=10, #early_stopping_rounds stop, jesli wartosc sie nie poprawia w 10 turach to stop\n             eval_set=[(imputed_X_test, val_y)], verbose=50) #verbose=10 ->co 10 wynik pokazuje\n# predykcja\npredictions = my_model.predict(imputed_X_test)\nprint(\"Mean Absolute Error po tuningu : \" + str(mean_absolute_error(predictions, val_y)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "56be0c0bf7c4a874af11699564978d41662a0a35",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Tuning learning_rate->im mniejszy tym wiecej krokow i dluzej sie liczy, ale zapobiega overfittingowi, mniejszy wplyw pojedynczego komponentu, bo przed dodaniem mnozymy prze mala wartosc learning_rate\n#Instead of getting predictions by simply adding up the predictions from each component model, we will multiply the predictions from each model by a small number before adding them in. This means each tree we add to the ensemble helps us less. In practice, this reduces the models propensity to overfit.\nmy_model = XGBRegressor(n_estimators=10000, learning_rate=0.005)\nmy_model.fit(imputed_X_train, train_y, early_stopping_rounds=10, \n             eval_set=[(imputed_X_test, val_y)], verbose=50)\n# predykcja\npredictions = my_model.predict(imputed_X_test)\nprint(\"Mean Absolute Error po tuningu learning_rate : \" + str(mean_absolute_error(predictions, val_y)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "69869bae227edfa1e1f26f85637a9c66d6a38785"
      },
      "cell_type": "code",
      "source": "#n_jobs informacja o ilosci rdzeni procesora do liczenia",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7e8ae068867ee1b74e78e25b180d6582c2739b52"
      },
      "cell_type": "markdown",
      "source": "# 4. Wykresy czesciowej zaleznosci (Partial Dependence Plots)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "47e2d424d0fc6fbfaa13feba8b48568b43e9b3d1",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Zmodyfikowalem kod, by bazowac na wczesniej stworzonych danych, po imputacji i po one-hot encodingu\n#Partial Dependence pokazuje zaleznosc miedzy wartoscia cechy, a wartoscia targetu, przy marginalizacji pozostalych cech\n#dzieki czemu mozna zobrazowac wplyw pojedynczych cech na wyniki, np wplyw wielkosci domu na jego cene\n#z dokumentacji sklearn:Partial dependence plots show the dependence between the target function [2] and a set of ‘target’ features, marginalizing over the values of all other features (the complement features). Due to the limits of human perception the size of the target feature set must be small (usually, one or two) thus the target features are usually chosen among the most important features '''\nfrom sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\nfrom sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence\n\ncols_to_use = one_hot_encoded_training_predictors.columns #nazwy cech\nfeatures_size=len(cols_to_use)#wymiar, ile mamy cech\n\nX=one_hot_encoded_training_predictors #X z uzwgledniniem one-hotow\ny=train_y\n\nmy_model = GradientBoostingRegressor()#obliczenia z uzwgledniniem GradientBoostingRegressor\nmy_model.fit(X, y)\n\nfor i in range(0,features_size,2): #petla by wyplotowac wszystkie wykresy zaleznosci, po 2 wykresy\n    my_plots = plot_partial_dependence(my_model, \n                                       features=[i,i+1], \n                                       X=X, \n                                       feature_names=cols_to_use, \n                                       grid_resolution=10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c91948a0ae8f94c70889bbb3ab8f17ec6f00a094"
      },
      "cell_type": "markdown",
      "source": "# 5. Pipelines"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6911e83955edea59a6ae4c5286db7129f79c888a",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Pipelines pozwalaja zamknac proces transformacji i predykcji w jednym pipeline (wywolanie jedna linijka kilku transformacji i predykcji)\n#mozliwe importy,make_pipeline automatycznie wypelnia nazwy, przy Pipeline trzeba je podac:\n#from sklearn.pipeline import make_pipeline \n#from sklearn.pipeline import Pipeline\n#Przyklad zapisu\n'''\npipeline = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf', SGDClassifier()),\n    ])\npredicted = pipeline.fit(Xtrain).predict(Xtrain)\n# Now evaluate all steps on test set\npredicted = pipeline.predict(Xtest)\n'''",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ee7e9e713a8342636f8f25debbfdb0f656f1f3e3",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#teraz juz pipeline z tutorialu\n#zaczynam od poczatku z wczytaniem danych, by juz nie mieszac przy tworzeniu nowego pipeline\nimport pandas as pd \nfrom sklearn.model_selection import train_test_split #import modulu to podzialu zbioru na treningowy i testowy\nfrom xgboost import XGBRegressor #import modelu XGBRegressor\nfrom sklearn.pipeline import make_pipeline #import pipeline\nfrom sklearn.impute import SimpleImputer #import imputatora\n\n#Wczytanie danych, podzial na testowe i treningowe\ndata = pd.read_csv('../input/melbourne-housing-snapshot/melb_data.csv')\ncols_to_use = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']\nX = data[cols_to_use]\ny = data.Price\ntrain_X, test_X, train_y, test_y = train_test_split(X, y)\n\n#Tworzenie pipeline\nmy_pipeline = make_pipeline(SimpleImputer(), XGBRegressor(n_estimators=1000, learning_rate=0.05, verbose=100, early_stopping_rounds=5))\n\n#Uruchomienie pipeline\nmy_pipeline.fit(train_X, train_y)\npredictions = my_pipeline.predict(test_X)\n\n#Sprawdzenie bledu MAE\nprint(\"Mean Absolute Error dla pipeline z XGBRegressorem : \" + str(mean_absolute_error(predictions, test_y)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ac4f051a6e364ebc9289cd67bd76f24c9f92b65e"
      },
      "cell_type": "markdown",
      "source": "# 6. Cross Validation"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "481686eee66a7231ea5dc75c423f781869472027",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Cross validation polega na uruchomieniu treningu i sprawdzeniu jego jakosci na kilku roznych podzbiorach glownego datasetu\n#Np. mamy 5 eksperymentow i bierzemy 80% jako zbior treningowy, a 20% jako walidacyjny -> sprawdzamy wynik\n#i tworzymy kolejny zbior, bierzymy czesc starego zbioru treningowego jako nowy walidacyjny, a stary walidacyjny dodajemy do treningowego\n#i tyle razy powtarzamy ile mamy eksperymentow\n\n#Bardzo przydatny przy mniejszych datasetach, gdy wylaczenie zbioru testowego moze wplywac na wyniki uzyskiwane w treningu, a predykcja dla zbioru\n#testowego moze byc niemiarodajna np.: zbior testowy zawiera szczegolne cechy, ktore w ogole nie wystepowaly w zbiorze treningowym\n#CV pozwala dobierac i badac parametry\n#Przy wiekszych datasetach wplyw ma dluzszy czas obliczen\n\n#wykorzystuje pipeline z punktu 5-ego\n#from sklearn.model_selection import GridSearchCV #inny model do CV\nfrom sklearn.model_selection import cross_val_score #modul do CV\nscores = cross_val_score(my_pipeline, X, y, scoring='neg_mean_absolute_error') #cross validation\nprint(scores) #ujemny wynik, bo w zalozeniu sklearn, im wiekszy wyniki tym lepszy model\nprint('Mean Absolute Error %2f' %(-1 * scores.mean())) #srednia z MAE z cross validation",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "19e014590ae5db1482d83c70f7f6face1d72a2ac"
      },
      "cell_type": "markdown",
      "source": "# 7. Data Leakage"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "1629686eb1da091d6457f44225778045dacff79a"
      },
      "cell_type": "code",
      "source": "#Leaky Predictors - mamy z nimi doczynienia, gdy w treningu wykorzystujemy dane (cechy), ktore nie beda dostepne w predykcji, a ktore silnie wplywaja \n#uzyskiwany wynik i model np.: dane treningowe zawierajace informacje o chorobie i objawach danej osoby zawieraja takze informacje, czy zostal przepisany lek\n#=>silna korelacja miedzy informacja czy zostal przepisany lek, a choroba => zly model, bo w predykcji nie bedzie informacji czy zostal przepisany lek\n#Trzeba usunac takie cechy, do ktorych nie bedzie dostepu podczas predykcji i ktore charakteryzuja sie silna korelacja i zaburzaja model\n\n#Leaky Validation Strategy - mamy z tym do czynienia, gdy przed podzialem na zbior treningowy i walidacyjny wykonujemy operacacje na danych imputacje\n#fit, usrednianie, podczas ktorych zbior walidacyjny wplywa na wartosci w zbiorze treningowym\n#=>uzyskujemy bardzo dobry wynik walidacji, ktory nie odpowiada rzeczywistosci\n#=>przed jakimis dzialaniami na datasetach trzeba odizolowac zbior treningowy i walidacyjny/testowy, by nie wplywaly na siebie\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fa2f5d4c9cfb9020331f011cfc119924526fe613",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#operujemy teraz na datsetcie AER_credit_card_data.csv\n#wczytanie, przeglad wczytanego datasetu\nimport pandas as pd\ndata = pd.read_csv('../input/aer-credit-card-datacsv/AER_credit_card_data.csv', \n                   true_values = ['yes'], #podmienia yes na boolowski True\n                   false_values = ['no']) #podmienia no na boolowski False\nprint(data.head())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d380e11f817f8ab61339b31d6cb3027b8606a82d",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "data.shape #zwraca wymiar datesetu -> maly wymiar-> musimy zastosowac cross validation",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "474710f38fad8d3b1a903f9aa6918752a7319ab9",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\ny = data.card\nX = data.drop(['card'], axis=1)\n\nmodeling_pipeline = make_pipeline(RandomForestClassifier())\ncv_scores = cross_val_score(modeling_pipeline, X, y, scoring='accuracy')\n#metryka accuracy zwraca stosunek ilosci poprawnych predykcji do sumy wszystkich predykcji\nprint(\"Cross-val accuracy: %f\" %cv_scores.mean()) #zwrocenie sredniej accuracy",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "723b72d52fc148f7f1cb4e050ac34fd7fadc1b47",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Uzyskany wynik budzi watpliwosci, czy nie wynika z Leaky Predictors\n#Sprawdzamy zaleznosc miedzy cecha expenditures i card\n\n#df = pd.DataFrame({'AAA' : [4,5,6,7], 'BBB' : [10,20,30,40],'CCC' : [100,50,-30,-50], 'DDD' : [False,True,True,True]})\n#df.AAA[~df.DDD]\n#jesli wartosc data.card==True to zwraca wartosc  data.expediture (w danym wierszu)\nexpenditures_cardholders = data.expenditure[data.card]\n#jesli wartosc (~data.card)==True to zwraca wartosc  data.expediture (w danym wierszu)\nexpenditures_noncardholders = data.expenditure[~data.card]\n\nprint('Udzial tych ktorzy nie mieli w wydatkow (?) wsrod posiadajcych karte: %.2f' \\\n      %(( expenditures_cardholders == 0).mean()))\nprint('Udzial tych ktorzy nie mieli wydatkow wsrod posiadajacych karte: %.2f' \\\n      %((expenditures_noncardholders == 0).mean()))\n\n#100%, osob ktore nie mialo karty nie mialo tez wydatkow i zaledwie 2% tych co mieli karte nie mialo\n#wydatkow\n#=>SILNA KORELACJA miedzy posiadaniem karty, a wydatkami ->zly model\n#->ktory glownie uwzglednia jedna ceche, a w predykcji moze jej nie byc!\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8a8c31a1f1fd65283976a9ee5b4e8e08da598055",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Uruchomienie modelu bez cech, ktore moga go zaburzac\npotential_leaks = ['expenditure', 'share', 'active', 'majorcards'] #odrzucone cechy\nX2 = X.drop(potential_leaks, axis=1) #wyrzucenie kolumn z tymi cechami\ncv_scores = cross_val_score(modeling_pipeline, X2, y, scoring='accuracy') #cv z accuracy\nprint(\"Cross-val accuracy: %f\" %cv_scores.mean())\n\n#Widoczne gorsze accuracy, ale model lepiej bedzie sie sprawdzal w predykcji\n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}